{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18224d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3130e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51c5b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1462.000000</td>\n",
       "      <td>1281.000000</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>1462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.031464</td>\n",
       "      <td>59886.273224</td>\n",
       "      <td>2.976744</td>\n",
       "      <td>0.506108</td>\n",
       "      <td>0.619015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.449717</td>\n",
       "      <td>15070.140389</td>\n",
       "      <td>1.681564</td>\n",
       "      <td>0.288465</td>\n",
       "      <td>0.485795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13929.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>49698.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>60148.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>69639.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>109899.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_courses_viewed  annual_income  interaction_count  \\\n",
       "count               1462.000000    1281.000000        1462.000000   \n",
       "mean                   2.031464   59886.273224           2.976744   \n",
       "std                    1.449717   15070.140389           1.681564   \n",
       "min                    0.000000   13929.000000           0.000000   \n",
       "25%                    1.000000   49698.000000           2.000000   \n",
       "50%                    2.000000   60148.000000           3.000000   \n",
       "75%                    3.000000   69639.000000           4.000000   \n",
       "max                    9.000000  109899.000000          11.000000   \n",
       "\n",
       "        lead_score    converted  \n",
       "count  1462.000000  1462.000000  \n",
       "mean      0.506108     0.619015  \n",
       "std       0.288465     0.485795  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.262500     0.000000  \n",
       "50%       0.510000     1.000000  \n",
       "75%       0.750000     1.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebda2dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lead_source', 'industry', 'number_of_courses_viewed', 'annual_income',\n",
       "       'employment_status', 'location', 'interaction_count', 'lead_score',\n",
       "       'converted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e411a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    retail\n",
       "Name: industry, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7b96d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6a4de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two features with the biggest correlation are: ('annual_income', 'interaction_count')\n",
      "The correlation value is: 0.048618416552580965\n"
     ]
    }
   ],
   "source": [
    "numerical_features = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "\n",
    "# Now, check the correlation between the specified pairs\n",
    "pairs = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "# Extract the correlation values for the pairs\n",
    "correlations = {pair: correlation_matrix.loc[pair[0], pair[1]] for pair in pairs}\n",
    "\n",
    "# Find the pair with the highest correlation\n",
    "max_correlation_pair = max(correlations, key=correlations.get)\n",
    "max_correlation_value = correlations[max_correlation_pair]\n",
    "\n",
    "# Display the results\n",
    "print(f\"The two features with the biggest correlation are: {max_correlation_pair}\")\n",
    "print(f\"The correlation value is: {max_correlation_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0845b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 877\n",
      "Validation size: 292\n",
      "Test size: 293\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume df is already loaded\n",
    "\n",
    "# Separate target and features\n",
    "X = df.drop(columns=['converted'])\n",
    "y = df['converted']\n",
    "\n",
    "# Split 60% train, 40% temp (which will be split again)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split remaining 40% equally into 20% val and 20% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))\n",
    "print(\"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b0987d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores:\n",
      "lead_source: 0.03\n",
      "industry: 0.0\n",
      "employment_status: 0.0\n",
      "location: 0.0\n",
      "\n",
      "Feature with highest mutual information: lead_source\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# Select categorical features\n",
    "categorical_features = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "\n",
    "# Convert categorical columns to numeric codes for MI computation\n",
    "X_train_cat = X_train[categorical_features].apply(lambda x: x.astype('category').cat.codes)\n",
    "\n",
    "# Compute mutual information\n",
    "mi_scores = mutual_info_classif(X_train_cat, y_train, random_state=42)\n",
    "\n",
    "# Pair variable names with their MI scores\n",
    "mi_results = {feature: round(score, 2) for feature, score in zip(categorical_features, mi_scores)}\n",
    "\n",
    "# Display all MI scores\n",
    "print(\"Mutual Information Scores:\")\n",
    "for feature, score in mi_results.items():\n",
    "    print(f\"{feature}: {score}\")\n",
    "\n",
    "# Find the variable with the highest MI score\n",
    "max_mi_feature = max(mi_results, key=mi_results.get)\n",
    "print(f\"\\nFeature with highest mutual information: {max_mi_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8a4a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_features = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "numerical_features = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "\n",
    "# Preprocess: Handle missing data and one-hot encode categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing categorical values\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))   # One-hot encode categorical features\n",
    "        ]), categorical_features),\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean'))  # Impute missing numerical values with mean\n",
    "        ]), numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define logistic regression model with specified parameters\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "val_accuracy = round(accuracy_score(y_val, y_val_pred), 2)\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fcad7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least useful feature is: annual_income\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# List of features\n",
    "all_features = ['lead_source', 'industry', 'employment_status', 'location', \n",
    "                'number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "\n",
    "# Categorical and numerical features\n",
    "categorical_features = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "numerical_features = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "\n",
    "# Preprocessor for handling missing values and encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_features),\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean'))\n",
    "        ]), numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Fit the model with all features\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get the baseline accuracy\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "baseline_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Track the accuracy difference for each feature\n",
    "accuracy_differences = {}\n",
    "\n",
    "for feature in all_features:\n",
    "    # Exclude one feature from the dataset\n",
    "    features_excluding_one = [f for f in all_features if f != feature]\n",
    "    \n",
    "    # Re-create the preprocessor and pipeline excluding the feature\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]), [f for f in categorical_features if f != feature]),\n",
    "            ('num', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='mean'))\n",
    "            ]), [f for f in numerical_features if f != feature])\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Fit the model and get accuracy\n",
    "    pipeline.fit(X_train[features_excluding_one], y_train)\n",
    "    y_val_pred = pipeline.predict(X_val[features_excluding_one])\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Calculate the difference in accuracy\n",
    "    accuracy_difference = baseline_accuracy - accuracy\n",
    "    accuracy_differences[feature] = accuracy_difference\n",
    "\n",
    "# Find the feature with the smallest accuracy difference\n",
    "least_useful_feature = min(accuracy_differences, key=accuracy_differences.get)\n",
    "print(f\"The least useful feature is: {least_useful_feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9b34cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: lead_source, Accuracy Difference: 0.013698630136986356\n",
      "Feature: industry, Accuracy Difference: 0.003424657534246589\n",
      "Feature: employment_status, Accuracy Difference: 0.003424657534246589\n",
      "Feature: location, Accuracy Difference: 0.0\n",
      "Feature: number_of_courses_viewed, Accuracy Difference: 0.07534246575342463\n",
      "Feature: annual_income, Accuracy Difference: -0.13356164383561642\n",
      "Feature: interaction_count, Accuracy Difference: 0.07534246575342463\n",
      "Feature: lead_score, Accuracy Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy differences for all features\n",
    "for feature, difference in accuracy_differences.items():\n",
    "    print(f\"Feature: {feature}, Accuracy Difference: {difference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40ffdfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of C is: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Different C values to try\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Initialize variables to track best accuracy and corresponding C\n",
    "best_accuracy = 0\n",
    "best_C = None\n",
    "\n",
    "# Train logistic regression for each C value\n",
    "for C in C_values:\n",
    "    # Create the logistic regression model with the current C value\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    \n",
    "    # Create pipeline (same preprocessing as before)\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Check if this is the best accuracy so far\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_C = C\n",
    "    elif accuracy == best_accuracy and C < best_C:  # In case of a tie, choose the smallest C\n",
    "        best_C = C\n",
    "\n",
    "# Display the best C value\n",
    "print(f\"The best value of C is: {best_C}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e247ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
